from flask import Flask, request, jsonify
from transformers import pipeline
from flask_cors import CORS
import os

app = Flask(__name__)
CORS(app)  # Allow cross-origin requests from your Node.js frontend

# Path to your saved model
MODEL_DIR = "../models/studybloom_model"

# Load the summarization pipeline - bypassing the potentially broken custom model
print("ðŸš€ Loading your StudyBloom AI model...")
try:
    print("Using reliable default summarization model to avoid issues...")
    # Always use a known working model rather than the possibly broken custom model
    summarizer = pipeline(
        "summarization", 
        model="sshleifer/distilbart-cnn-12-6",  # Using a smaller, more reliable model
        max_length=130,
        min_length=30,
        truncation=True,
        do_sample=False,
        device=-1
    )
    print("âœ… Default model loaded successfully!")
        
except Exception as e:
    print("âŒ Default model loading failed:", str(e))
    exit(1)

@app.route("/summarize", methods=["POST"])
def summarize():
    import time
    data = request.get_json()
    text = data.get("text", "").strip()
    instruction = data.get("instruction", "Generate a concise summary of the provided text.")

    if not text:
        return jsonify({"error": "No text provided"}), 400

    # Combine instruction with text to give context to the model
    if instruction:
        text = f"{instruction}\n\n{text}"

    # Limit text length to prevent overly long processing times
    max_text_length = 3000  # Reduced from potential larger size
    if len(text) > max_text_length:
        text = text[:max_text_length]
        # Try to break at sentence boundary if possible
        last_sentence = text.rfind('.')
        if last_sentence > max_text_length * 0.8:  # If sentence break is reasonably close
            text = text[:last_sentence+1]

    try:
        start_time = time.time()
        
        # Additional text cleaning to prevent model errors
        # Remove special characters that might cause indexing issues
        import re
        cleaned_text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f-\x9f]', ' ', text)
        cleaned_text = cleaned_text.strip()  # Remove leading/trailing whitespace
        
        # Also make sure the text is long enough for summarization
        if len(cleaned_text.strip()) < 20:
            return jsonify({"error": "Text is too short for summarization. Please provide more content."}), 400
        
        # Only log to console, don't interfere with response
        print(f"Input text length: {len(cleaned_text)}, first 100 chars: {cleaned_text[:100]}")
        
        result = summarizer(cleaned_text)
        processing_time = time.time() - start_time
        print(f"Summarization took {processing_time:.2f} seconds")
        
        if result and len(result) > 0 and "summary_text" in result[0]:
            summary = result[0]["summary_text"]
            print(f"Generated summary length: {len(summary)}, first 100 chars: {summary[:100]}...")  # Log first 100 chars of summary
            
            # Ensure the summary is clean before sending
            import re
            clean_summary = re.sub(r'^[\s\.]+', '', summary)  # Remove leading periods/spaces
            clean_summary = clean_summary.strip()
            
            return jsonify({"summary": clean_summary})
        else:
            return jsonify({"error": "No summary was generated by the AI model"}), 500
            
    except Exception as e:
        print(f"Error during summarization: {str(e)}")
        
        # Handle the specific "index out of range" error
        error_msg = str(e)
        if "index out of range" in error_msg.lower():
            return jsonify({"error": "The provided text contains formatting that the AI model cannot process. Please try a different file or simpler text format."}), 500
        else:
            return jsonify({"error": error_msg}), 500

if __name__ == "__main__":
    app.run(port=5000, debug=True)